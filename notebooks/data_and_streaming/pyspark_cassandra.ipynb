{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "\n",
    "cluster = Cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "session = cluster.connect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Row(release_version='3.11.11')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(\"SELECT release_version FROM system.local\").one()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(userid='1234', item_count=5, last_update_timestamp=datetime.datetime(2022, 2, 21, 8, 13, 46, 714000)),\n Row(userid='9876', item_count=2, last_update_timestamp=datetime.datetime(2022, 2, 21, 8, 13, 46, 705000))]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(\"select * from store.shopping_cart\").all()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(userid='1234', item_count=5, last_update_timestamp=datetime.datetime(2022, 2, 21, 8, 13, 46, 714000)),\n Row(userid='9876', item_count=2, last_update_timestamp=datetime.datetime(2022, 2, 21, 8, 13, 46, 705000))]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.set_keyspace('store')\n",
    "\n",
    "session.execute(\"select * from shopping_cart\").all()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(last_name='Rodriguez', first_name='Mary', address=('7712 E. Broadway', 'Tucson', 'AZ', 85715), addresses=OrderedMapSerializedKey([('home', address(street='7112 E. Broadway', city='Tucson', state='AZ', zip_code=85715))]), emails=SortedSet(['mary.Rodriguez.AZ@gmail.com', 'mary@example.com']), id=UUID('bcc50922-fd55-4811-a123-f2af786cc73a'), login_sessions=OrderedMapSerializedKey([(UUID('3246b850-92ee-11ec-aac8-11ca1d03e536'), 13), (UUID('3246b851-92ee-11ec-aac8-11ca1d03e536'), 18)]), middle_initial=None, phone_numbers=['480-111-1111'], title=None),\n Row(last_name='Nguyen', first_name='Bill', address=None, addresses=None, emails=None, id=None, login_sessions=None, middle_initial='R', phone_numbers=None, title='Mr.'),\n Row(last_name='Nguyen', first_name='Wanda', address=None, addresses=None, emails=None, id=None, login_sessions=None, middle_initial=None, phone_numbers=None, title='Mrs.')]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(\"select * from user\").all()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JAVA_HOME=/usr/local/lib/java/Contents/Home\n"
     ]
    }
   ],
   "source": [
    "%env JAVA_HOME=/usr/local/lib/java/Contents/Home"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/kimmy.liu/Workspace/playz3/.venv/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/kimmy.liu/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/kimmy.liu/.ivy2/jars\n",
      "com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-238bd38b-12bf-4959-b468-15b865255d45;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.datastax.spark#spark-cassandra-connector_2.12;3.1.0 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-driver_2.12;3.1.0 in central\n",
      "\tfound com.datastax.oss#java-driver-core-shaded;4.12.0 in central\n",
      "\tfound com.datastax.oss#native-protocol;1.5.0 in central\n",
      "\tfound com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.26 in central\n",
      "\tfound io.dropwizard.metrics#metrics-core;4.1.18 in central\n",
      "\tfound org.hdrhistogram#HdrHistogram;2.1.12 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
      "\tfound com.github.spotbugs#spotbugs-annotations;3.1.12 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound com.datastax.oss#java-driver-mapper-runtime;4.12.0 in central\n",
      "\tfound com.datastax.oss#java-driver-query-builder;4.12.0 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.10 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.11 in central\n",
      ":: resolution report :: resolve 432ms :: artifacts dl 46ms\n",
      "\t:: modules in use:\n",
      "\tcom.datastax.oss#java-driver-core-shaded;4.12.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-mapper-runtime;4.12.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-query-builder;4.12.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]\n",
      "\tcom.datastax.oss#native-protocol;1.5.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-driver_2.12;3.1.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector_2.12;3.1.0 from central in [default]\n",
      "\tcom.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tio.dropwizard.metrics#metrics-core;4.1.18 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.10 from central in [default]\n",
      "\torg.hdrhistogram#HdrHistogram;2.1.12 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.11 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.26 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   18  |   0   |   0   |   0   ||   18  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-238bd38b-12bf-4959-b468-15b865255d45\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 18 already retrieved (0kB/12ms)\n",
      "22/02/22 23:43:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/plain": "<SparkContext master=local[*] appName=local>",
      "text/html": "\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://css-c02gf1fpmd6r:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>local</code></dd>\n            </dl>\n        </div>\n        "
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.setAppName('local')\n",
    "conf.set('spark.sql.extensions', 'com.datastax.spark.connector.CassandraSparkExtensions')\n",
    "conf.set('spark.jars.packages', 'com.datastax.spark:spark-cassandra-connector_2.12:3.1.0')\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "sc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x1266069a0>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://css-c02gf1fpmd6r:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>local</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession(sparkContext=sc)\n",
    "\n",
    "spark.conf.set(\"spark.sql.catalog.mycatalog\", \"com.datastax.spark.connector.datasource.CassandraCatalog\")\n",
    "\n",
    "spark"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS mycatalog.testks WITH DBPROPERTIES (class='SimpleStrategy',replication_factor='1')\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         namespace|\n",
      "+------------------+\n",
      "|       reservation|\n",
      "|            testks|\n",
      "|           cadence|\n",
      "|             hotel|\n",
      "|             store|\n",
      "|cadence_visibility|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('show namespaces from mycatalog').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "df = spark.read.table(\"mycatalog.store.shopping_cart\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------------------+\n",
      "|userid|item_count|last_update_timestamp|\n",
      "+------+----------+---------------------+\n",
      "|  9876|         2| 2022-02-21 16:13:...|\n",
      "|  1234|         5| 2022-02-21 16:13:...|\n",
      "+------+----------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|userid|\n",
      "+------+\n",
      "|  9876|\n",
      "|  1234|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"userid\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:=======================>                                (16 + 16) / 38]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+\n",
      "|summary|           userid|        item_count|\n",
      "+-------+-----------------+------------------+\n",
      "|  count|                2|                 2|\n",
      "|   mean|           5555.0|               3.5|\n",
      "| stddev|6110.816803014143|2.1213203435596424|\n",
      "|    min|             1234|                 2|\n",
      "|    25%|           1234.0|                 2|\n",
      "|    50%|           1234.0|                 2|\n",
      "|    75%|           9876.0|                 5|\n",
      "|    max|             9876|                 5|\n",
      "+-------+-----------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.summary().show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "[('userid', 'string'),\n ('item_count', 'int'),\n ('last_update_timestamp', 'timestamp')]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "userDf = spark.read.format(\"org.apache.spark.sql.cassandra\").option(\"keyspace\", \"store\") \\\n",
    "    .option(\"table\", \"user\")\\\n",
    "    .load()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- last_name: string (nullable = false)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- address: struct (nullable = true)\n",
      " |    |-- 0: string (nullable = true)\n",
      " |    |-- 1: string (nullable = true)\n",
      " |    |-- 2: string (nullable = true)\n",
      " |    |-- 3: integer (nullable = true)\n",
      " |-- addresses: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: struct (valueContainsNull = true)\n",
      " |    |    |-- street: string (nullable = true)\n",
      " |    |    |-- city: string (nullable = true)\n",
      " |    |    |-- state: string (nullable = true)\n",
      " |    |    |-- zip_code: integer (nullable = true)\n",
      " |-- emails: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- login_sessions: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: integer (valueContainsNull = true)\n",
      " |-- middle_initial: string (nullable = true)\n",
      " |-- phone_numbers: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userDf.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+-----+\n",
      "|last_name|first_name|             address|           addresses|              emails|                  id|      login_sessions|middle_initial| phone_numbers|title|\n",
      "+---------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+-----+\n",
      "|Rodriguez|      Mary|{7712 E. Broadway...|{home -> {7112 E....|[mary.Rodriguez.A...|bcc50922-fd55-481...|{3246b850-92ee-11...|          null|[480-111-1111]| null|\n",
      "|   Nguyen|      Bill|                null|                  {}|                  []|                null|                  {}|             R|            []|  Mr.|\n",
      "|   Nguyen|     Wanda|                null|                  {}|                  []|                null|                  {}|          null|            []| Mrs.|\n",
      "+---------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userDf.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+---------+------+----+--------------+--------------+-------------+-----+\n",
      "|last_name|first_name|address|addresses|emails|  id|login_sessions|middle_initial|phone_numbers|title|\n",
      "+---------+----------+-------+---------+------+----+--------------+--------------+-------------+-----+\n",
      "|   Nguyen|      Bill|   null|       {}|    []|null|            {}|             R|           []|  Mr.|\n",
      "+---------+----------+-------+---------+------+----+--------------+--------------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnull\n",
    "\n",
    "userDf.filter(~isnull(userDf['middle_initial'])).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|last_name|members|\n",
      "+---------+-------+\n",
      "|   Nguyen|      2|\n",
      "|Rodriguez|      1|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "familyDf = userDf.groupby(\"last_name\").agg({\"*\": \"count\"}).withColumnRenamed(\"COUNT(1)\", \"members\")\n",
    "familyDf.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "session.execute(\"CREATE TABLE IF NOT EXISTS store.family (last_name text primary key, members int)\").all()\n",
    "\n",
    "familyDf.write.format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"keyspace\", \"store\") \\\n",
    "    .option(\"table\", \"family\").save()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(last_name='Rodriguez', members=1), Row(last_name='Nguyen', members=2)]"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(\"select * from store.family\").all()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}